{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22edc94f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the raw file path: /Users/lymcr/Desktop/50f809494a3d46f695f1f357bf1366d9.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7y/46jvy8212rg8ctzpvvkscccw0000gn/T/ipykernel_1759/1832753302.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_by_date['PartWeightedPremium'] = ((filtered_by_date['OTRate']*(filtered_by_date['TimeWorkedInHours']+filtered_by_date['DriveTimeHours']))/filtered_by_date['TotalTimeWorked'])*filtered_by_date['OTTime']*0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the output dir: /Users/lymcr/Desktop/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from a CSV file\n",
    "input_prompt = input(\"Enter the raw file path: \")\n",
    "df = pd.read_csv(input_prompt, parse_dates=['DateOfService'])\n",
    "\n",
    "# Typecast date-time\n",
    "df['DateOfService'] = df['DateOfService'].dt.date\n",
    "df['DateTimeTo'] = pd.to_datetime(df['DateTimeTo'])\n",
    "df['DateTimeFrom'] = pd.to_datetime(df['DateTimeFrom'])\n",
    "\n",
    "\n",
    "# New column with FullName for exporting\n",
    "df['ProviderFullName'] = df['ProviderFirstName'] + ' ' + df['ProviderLastName']\n",
    "\n",
    "# Make new column for Drive Time in hours\n",
    "df['DriveTimeHours'] = df['DriveTimeMinutes']/60\n",
    "\n",
    "# Get list of provider unique ids\n",
    "unique_id = df['ProviderId'].unique()\n",
    "\n",
    "# Group by Provider and Date & Calculate Total daily work time and Total daily drive time per day\n",
    "daily_hours = df.groupby(['ProviderId', 'ProviderFullName','DateOfService']).agg({'TimeWorkedInHours':'sum','DriveTimeHours':'sum'}).reset_index()\n",
    "\n",
    "# Add new col with the daily total for both Work and Drive time\n",
    "daily_hours = daily_hours.assign(TotalTimeWorked = daily_hours['TimeWorkedInHours'] + daily_hours['DriveTimeHours'])\n",
    "\n",
    "# Drop col from daily_hours to not get duplicates when merged to original data later\n",
    "daily_hours = daily_hours.drop(['TimeWorkedInHours','DriveTimeHours'], axis=1)\n",
    "\n",
    "\n",
    "# Drop unnecessary cols in the original dataframe\n",
    "df = df.drop(['ProviderFullName','Id','ClientId','ClientFirstName', 'ClientLastName','ClientContactLabels',\n",
    "                   'ProviderContactLabels', 'AuthorizationId', 'AuthorizationResourceId', 'ProcedureCodeId', 'ProcedureCode', 'ProcedureCodeDescription',\n",
    "                    'CodeLabels','Location','TimeWorkedInMins','ProviderFirstName','ProviderLastName',\n",
    "              'UnitsOfService','DriveTimeMinutes','Mileage','BillingLabels','ClientSignature','ProviderSignature',\n",
    "         'PayorId','PayorName','ProviderCharges','RateProviderDriveMileage','ProviderDriveCharge','ProviderMileageCharge',\n",
    "         'ProviderChargesTotal','IsVoid','IsLocked'], axis=1)\n",
    "\n",
    "# Merge daily_hours with ogirinal data based on ProvideId and DateOfService\n",
    "merged_df = pd.merge(df, daily_hours, on=['ProviderId', 'DateOfService'])\n",
    "\n",
    "# Get rid of rows on days that have no OT\n",
    "ot_df = merged_df[merged_df['TotalTimeWorked'] > 8]\n",
    "\n",
    "\n",
    "# Drop exempted providers with hourly rates = 0\n",
    "ot_df = ot_df[ot_df['RateProvider'] > 0]\n",
    "\n",
    "# Get list of provider unique ids\n",
    "unique_id = ot_df['ProviderId'].unique()\n",
    "\n",
    "# Group by ProviderId & DateOfService after merge\n",
    "temp_group = ot_df.groupby(['ProviderId','DateOfService','ProviderFullName','RateProvider','RateProviderDriveHourly','TotalTimeWorked']).agg({'TimeWorkedInHours':'sum','DriveTimeHours':'sum'}).reset_index()\n",
    "\n",
    "# Add new col for OT time of date\n",
    "temp_group = temp_group.assign(OTTime = temp_group['TotalTimeWorked'] - 8)\n",
    "\n",
    "# Add new col that finds weighted rate of the date\n",
    "temp_group['OTRate'] = (temp_group['TimeWorkedInHours']*temp_group['RateProvider']+temp_group['DriveTimeHours']*temp_group['RateProviderDriveHourly'])/(temp_group['DriveTimeHours']+temp_group['TimeWorkedInHours'])\n",
    "\n",
    "# Add empty col PartWeightedRate with partial weighted rate of the date from the work shift/row\n",
    "temp_group['PartWeightedPremium'] = \"\"\n",
    "\n",
    "# Add empty col for OT premium\n",
    "temp_group['OTPremium'] = \"\"\n",
    "\n",
    "\n",
    "# Loop through list of OT rows, start with going by provider\n",
    "for n in unique_id:\n",
    "    # For each provider, filter the temp data by the id\n",
    "    filtered_by_id = temp_group[temp_group['ProviderId'] == n]\n",
    "    # Get list of unique dates for the CURRENT provider\n",
    "    unique_date = filtered_by_id['DateOfService'].unique()\n",
    "    # For each date for the current provider\n",
    "    for d in unique_date:\n",
    "        # For each date, filter the temp data by the date\n",
    "        filtered_by_date = filtered_by_id[filtered_by_id['DateOfService'] == d]\n",
    "        # Calc the daily part of weighted rate for the entry\n",
    "        filtered_by_date['PartWeightedPremium'] = ((filtered_by_date['OTRate']*(filtered_by_date['TimeWorkedInHours']+filtered_by_date['DriveTimeHours']))/filtered_by_date['TotalTimeWorked'])*filtered_by_date['OTTime']*0.5\n",
    "        # Copy PartWeightedPremium from filtered_by_date to original table\n",
    "        temp_group.loc[(temp_group['ProviderId'] == n) & (temp_group['DateOfService'] == d), 'PartWeightedPremium'] = filtered_by_date['PartWeightedPremium']\n",
    "        # Get the daily weighted rate\n",
    "        daily_premium = filtered_by_date['PartWeightedPremium'].sum()\n",
    "        # Write the daily rate back to temp_group/og data        \n",
    "        temp_group.loc[(temp_group['ProviderId'] == n) & (temp_group['DateOfService'] == d), 'OTPremium'] = daily_premium\n",
    "\n",
    "# print for quick test\n",
    "\n",
    "temp_pivot = pd.pivot_table(temp_group, values=['PartWeightedPremium'], index=['ProviderFullName','DateOfService','OTTime'], aggfunc='sum')\n",
    "# print(temp_pivot)\n",
    "temp_2 = temp_pivot.reset_index()\n",
    "temp_2 = temp_2.groupby(['ProviderFullName']).agg({'OTTime':'sum','PartWeightedPremium':'sum'}).reset_index()\n",
    "\n",
    "# Rename PartWeightedPremium into OTPremium to reflect sum\n",
    "temp_2 = temp_2.rename(columns={'PartWeightedPremium': 'OTPremium'})\n",
    "\n",
    "# write to new file\n",
    "output_prompt = input(\"Enter the output dir: \")\n",
    "output_filename = 'overtime_result.csv'\n",
    "temp_2.to_csv(output_prompt + output_filename, mode='w', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04997427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4451bd39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
